{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy1UU44WTfZo",
        "outputId": "886c1987-65c2-47ed-edeb-b5497dbba4b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resume = \"\"\"\n",
        "I am a Computer Science student with knowledge in Python, SQL, and Machine Learning.\n",
        "I have worked on data analysis, data visualization, and basic machine learning models.\n",
        "I have experience using Python libraries such as NumPy, Pandas, and Matplotlib.\n",
        "I have basic knowledge of NLP and have built small projects related to text classification.\n",
        "I am a quick learner and interested in improving my technical and analytical skills.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "odOJXyWUV_KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_description = \"\"\"\n",
        "We are looking for a candidate with strong skills in Python, Machine Learning, and Data Analysis.\n",
        "The candidate should have experience with SQL, data preprocessing, and natural language processing.\n",
        "Knowledge of deep learning, model optimization, and data visualization is a plus.\n",
        "The role involves building predictive models and working with large datasets.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "wPL54V2NWA8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
        "    words = text.split()\n",
        "    stop_words = stopwords.words('english')\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "resume_clean = clean_text(resume)\n",
        "job_clean = clean_text(job_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu169U9-WD6D",
        "outputId": "94a8d13c-eddd-491b-a7b3-08aea97b1736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform([resume_clean, job_clean])\n"
      ],
      "metadata": {
        "id": "m_P6Jr08WTLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity = cosine_similarity(vectors[0:1], vectors[1:2])\n",
        "match_percentage = round(similarity[0][0] * 100, 2)\n",
        "\n",
        "print(\"Match Percentage:\", match_percentage, \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izC216AhWWhX",
        "outputId": "83bd86dc-4c0c-4f64-db5c-b3cfcf2aa34e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Match Percentage: 21.99 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resume_words = set(resume_clean.split())\n",
        "job_words = set(job_clean.split())\n",
        "\n",
        "missing_skills = job_words - resume_words\n",
        "\n",
        "print(\"\\nMissing Skills:\")\n",
        "for skill in missing_skills:\n",
        "    print(\"-\", skill)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un766GU0WZS9",
        "outputId": "daf6fc37-d64e-47c0-8fd3-db3c55900101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing Skills:\n",
            "- large\n",
            "- building\n",
            "- role\n",
            "- natural\n",
            "- preprocessing\n",
            "- candidate\n",
            "- optimization\n",
            "- strong\n",
            "- deep\n",
            "- datasets\n",
            "- model\n",
            "- analysisthe\n",
            "- processingknowledge\n",
            "- looking\n",
            "- models\n",
            "- language\n",
            "- plusthe\n",
            "- predictive\n",
            "- working\n",
            "- involves\n"
          ]
        }
      ]
    }
  ]
}